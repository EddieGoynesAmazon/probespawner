# Linux performance metrics: top, iostat, vmstat and netstat to Elasticsearch

This example shows how ship to elasticsearch a set of linux system perfomance indicators using top, vmstat, iostat and netstat.  
* The information will be obtained from periodical netstat collections.
* Data will be indexed in Elasticsearch.  
* Display of the graph will be done using Kibana

[This is an extension of a previous example](https://github.com/filipealmeida/probespawner/blob/master/docs/001.netstat.to.elasticsearch.qbana.force.directed.graph.md).

Something like this:  
![](https://github.com/filipealmeida/probespawner/blob/master/docs/probespawner.top.iostat.netstat.top.elasticsearch.png)

You will need to have installed:
* probespawner - https://github.com/filipealmeida/probespawner
* elasticsearch + kibana - https://www.elastic.co/

We will now:  
1. Define netstat input
2. Define netstat statistics input
3. Define top input
4. Define iostat input
5. Define vmstat input
6. Define elasticsearch output
7. Define input with all these probes (inputs)
8. Save the JSON file
9. Run probespawner
10. Access kibana dashboard

##### 1. Define netstat input:
The input will be configured to issue a `netstat -ntce` and start parsing and loading to the outputs (`-c` flag is continuous mode, data every second).  
The JSON block will be as follows:

```
    "LinuxNetstatNTCInput": {
       "description": "LinuxNetstatNTCInput",
       "probemodule": { "module": "netstatntc", "name" : "LinuxNetstatNTC" },
       "output": ["TestOutput"],
       "command": "netstat -ntce",
       "interval": 10
    }
```
##### 2. Define netstat statistics input
The netstats statistics will be collected every minute:  
```
    "LinuxNetstatSInput": {
       "description": "LinuxNetstatSInput",
       "probemodule": { "module": "netstats", "name" : "LinuxNetstatS" },
       "output": ["TestOutput"],
       "command": "netstat -s",
       "interval": 60
    }
```
##### 3. Define top input
Take a quick look at the `command` in the JSON block below.  
Top will display the incremental of all threads with a delay of 5 seconds, 20 samples.  
Interval is disregarded since top's execution will always exceed the 10 seconds defined.  
This means that as soon as the 20 samples are collected, top will be executed by probespawner immediatelly.
```
    "TopInput": {
       "description": "TopInput",
       "probemodule": { "module": "linuxtopprobe", "name" : "LinuxTopProbe" },
       "output": ["TestOutput"],
       "command": "top -Hbi -n20 -d5 -w512",
       "interval": 10
    }
```
##### 4. Define iostat input
`iostat` will use the generic execution probe.  
It'll parse the lines starting with a device name (see `regex`) and index the fields defined there.  
Pay attention to the `metrics` array. That means that for each of those fields, a new document will be created. More on this at the bottom (kibana heading)
```
    "IOstatInput": {
       "description": "ExecInput",
       "probemodule": { "module": "execprobe", "name" : "ExecProbe" },
       "output": ["TestOutput"],
       "command": "iostat -k 1",
       "interval": 1,
       "regex": "^(?P<device>[a-zA-Z0-9]+?)[\t ]+(?P<tps>[0-9,.]+)[\t ]+(?P<kbreads>[0-9,.]+)[\t ]+(?P<kbwrites>[0-9,.]+)[\t ]+(?P<kb_read>[0-9,.]+)[\t ]+(?P<kb_wrtn>[0-9,.]+)",
       "metrics": ["tps", "kbreads", "kbwrites", "kb_read", "kb_wrtn"],
       "terms": [],
       "decimalMark": ","
    }
```
##### 5. Define vmstat input
Analogous to the `iostat` input.
```
    "VmstatInput": {
       "description": "ExecInput",
       "probemodule": { "module": "execprobe", "name" : "ExecProbe" },
       "output": ["TestOutput"],
       "command": "vmstat 1",
       "interval": 1,
       "regex": "^([\t ]+?)(?P<runnable>[0-9]+)[\t ]+(?P<blocked>[0-9]+)[\t ]+(?P<swpd>[0-9]+)[\t ]+(?P<free>[0-9]+)[\t ]+(?P<buf>[0-9]+)[\t ]+(?P<cache>[0-9]+)[\t ]+(?P<si>[0-9]+)[\t ]+(?P<so>[0-9]+)[\t ]+(?P<bi>[0-9]+)[\t ]+(?P<bo>[0-9]+)[\t ]+(?P<in>[0-9]+)[\t ]+(?P<cs>[0-9]+)[\t ]+(?P<us>[0-9]+)[\t ]+(?P<sy>[0-9]+)[\t ]+(?P<id>[0-9]+)[\t ]+(?P<wa>[0-9]+)[\t ]+(?P<st>[0-9]+)",
       "metrics": ["runnable","blocked","swpd","free","buf","cache","si","so","bi","bo","in","cs","us","sy","id","wa","st"]
    }
```
##### 6. Define elasticsearch output
You may have noticed at the blocks above the `TestOutput` defined as the probe's out.  
Our Elasticsearch clustername here is "arama" (which stands for search in turkish).  
Index settings and mappings will not be debated here.  
`TestOutput` is the following elasticsearch output:
```
    "TestOutput": {
      "class": "elasticsearch",
      "outputmodule": { "module": "jelh", "name" : "Elasticsearch" },
      "cluster" : "arama",
      "type": "linuxmetrics",
      "host" : "suchhost",
      "port" : 9300,
      "bulkActions": 1000,
      "indexPrefix": "linuxindex",
      "index_settings": {
        "index" : {
          "analysis" : {
            "analyzer" : {
              "default" : {
                "type" : "standard",
                "filter": ["standard", "asciifolding","lowercase"]
              },
              "sortable": {
                "tokenizer": "keyword",
                "filter": ["lowercase"]
              }
            }
          }
        }
      },
      "type_mapping": {
        "linuxmetrics": { "properties" : {
            "@timestamp" : { "type" : "date" },
            "WCHAN" : {"type" : "string", "index" : "not_analyzed"},
            "USER" : {"type" : "string", "index" : "not_analyzed"},
            "Flags" : {"type" : "string", "index" : "not_analyzed"},
            "metric" : {"type" : "string", "index" : "not_analyzed"},
            "class" : {"type" : "string", "index" : "not_analyzed"},
            "host" : {"type" : "string", "index" : "not_analyzed"},
            "value" : {"type" : "double" }
            }
          }
      }
    },
```
##### 7. Define input with all these probes (inputs)
The input will be all the probes defined above:
```
    "input": ["VmstatInput","TopInput","LinuxNetstatSInput","LinuxNetstatNTCInput","IOstatInput"],
```
##### 8. Save the JSON file
We will call it `linux.monitoring.top.netstat.vmstat.iostat.to.elasticsearch.json`.
[You can download it by clicking here](https://github.com/filipealmeida/probespawner/blob/master/examples/linux.monitoring.top.netstat.vmstat.iostat.to.elasticsearch.json).  
It's also shipped in the probespawner's package, `examples` directory.
##### 9. Run probespawner
After running you'll see the probes and elasticsearch connections being established.  
You can change `probespawner.ini` to increase or decrease logging level for your convenience.  
```
user@foo:~/code/probespawner-master$ ./probespawner.sh examples/linux.monitoring.top.netstat.vmstat.iostat.to.elasticsearch.json
"my" variable $jythonHome masks earlier declaration in same scope at /usr/bin/jython line 15.

2015-06-04 17:34:55,479 execprobe      INFO     Got regex for parsing: ^([	 ]+?)(?P<runnable>[0-9]+)[	 ]+(?P<blocked>[0-9]+)[	 ]+(?P<swpd>[0-9]+)[	 ]+(?P<free>[0-9]+)[	 ]+(?P<buf>[0-9]+)[	 ]+(?P<cache>[0-9]+)[	 ]+(?P<si>[0-9]+)[	 ]+(?P<so>[0-9]+)[	 ]+(?P<bi>[0-9]+)[	 ]+(?P<bo>[0-9]+)[	 ]+(?P<in>[0-9]+)[	 ]+(?P<cs>[0-9]+)[	 ]+(?P<us>[0-9]+)[	 ]+(?P<sy>[0-9]+)[	 ]+(?P<id>[0-9]+)[	 ]+(?P<wa>[0-9]+)[	 ]+(?P<st>[0-9]+)
2015-06-04 17:34:55,684 execprobe      INFO     Got regex for parsing: ^(?P<device>[a-zA-Z0-9]+?)[	 ]+(?P<tps>[0-9,.]+)[	 ]+(?P<kbreads>[0-9,.]+)[	 ]+(?P<kbwrites>[0-9,.]+)[	 ]+(?P<kb_read>[0-9,.]+)[	 ]+(?P<kb_wrtn>[0-9,.]+)
2015-06-04 17:34:55,835 dummyprobe     INFO     Started cycle at 2015-06-04T17:34:55.823+01:00
2015-06-04 17:34:55,844 dummyprobe     INFO     Started cycle at 2015-06-04T17:34:55.844+01:00
2015-06-04 17:34:56,025 dummyprobe     INFO     Started cycle at 2015-06-04T17:34:56.025+01:00
2015-06-04 17:34:56,141 dummyprobe     INFO     Started cycle at 2015-06-04T17:34:56.142+01:00
2015-06-04 17:34:56,520 jelh           INFO     Setting Elasticsearch options: cluster.name = arama
2015-06-04 17:34:56,525 jelh           INFO     Setting Elasticsearch options: cluster.name = arama
2015-06-04 17:34:56,523 jelh           INFO     Setting Elasticsearch options: cluster.name = arama
2015-06-04 17:34:56,549 jelh           INFO     Setting Elasticsearch options: cluster.name = arama
2015-06-04 17:34:56,684 dummyprobe     INFO     Started cycle at 2015-06-04T17:34:56.685+01:00
2015-06-04 17:34:56,703 jelh           INFO     Setting Elasticsearch options: cluster.name = arama
Jun 04, 2015 5:34:57 PM org.elasticsearch.plugins.PluginsService <init>
INFO: [Mastermind] loaded [], sites []
Jun 04, 2015 5:34:57 PM org.elasticsearch.plugins.PluginsService <init>
INFO: [Marvin Flumm] loaded [], sites []
Jun 04, 2015 5:34:57 PM org.elasticsearch.plugins.PluginsService <init>
INFO: [Perseus] loaded [], sites []
Jun 04, 2015 5:34:57 PM org.elasticsearch.plugins.PluginsService <init>
INFO: [Ritchie Gilmore] loaded [], sites []
Jun 04, 2015 5:34:57 PM org.elasticsearch.plugins.PluginsService <init>
INFO: [Tarot] loaded [], sites []
2015-06-04 17:35:02,540 jelh           INFO     Creating index linuxindex-2015.06.04
2015-06-04 17:35:02,543 jelh           INFO     Index settings: {"index":{"analysis":{"analyzer":{"sortable":{"tokenizer":"keyword","filter":["lowercase"]},"default":{"filter":["standard","asciifolding","lowercase"],"type":"standard"}}}}}
2015-06-04 17:35:02,637 jelh           INFO     Creating index linuxindex-2015.06.04
2015-06-04 17:35:02,641 jelh           INFO     Index settings: {"index":{"analysis":{"analyzer":{"sortable":{"tokenizer":"keyword","filter":["lowercase"]},"default":{"filter":["standard","asciifolding","lowercase"],"type":"standard"}}}}}
2015-06-04 17:35:03,086 jelh           INFO     Setting mapping for linuxindex-2015.06.04/linuxmetrics - {"linuxmetrics":{"properties":{"class":{"index":"not_analyzed","type":"string"},"@timestamp":{"type":"date"},"metric":{"index":"not_analyzed","type":"string"},"Flags":{"index":"not_analyzed","type":"string"},"value":{"type":"double"},"WCHAN":{"index":"not_analyzed","type":"string"},"USER":{"index":"not_analyzed","type":"string"},"host":{"index":"not_analyzed","type":"string"}}}}
2015-06-04 17:35:03,433 jelh           WARNING  org.elasticsearch.indices.IndexAlreadyExistsException: [linuxindex-2015.06.04] already exists
2015-06-04 17:35:03,434 jelh           WARNING  Index linuxindex-2015.06.04 already exists, this should be harmless
2015-06-04 17:35:03,434 jelh           INFO     Setting mapping for linuxindex-2015.06.04/linuxmetrics - {"linuxmetrics":{"properties":{"class":{"index":"not_analyzed","type":"string"},"@timestamp":{"type":"date"},"metric":{"index":"not_analyzed","type":"string"},"Flags":{"index":"not_analyzed","type":"string"},"value":{"type":"double"},"WCHAN":{"index":"not_analyzed","type":"string"},"USER":{"index":"not_analyzed","type":"string"},"host":{"index":"not_analyzed","type":"string"}}}}
2015-06-04 17:35:04,391 jelh           INFO     Flushing 109 records
2015-06-04 17:35:04,671 dummyprobe     INFO     Finished cycle at 2015-06-04T17:35:04.671+01:00
2015-06-04 17:35:04,674 dummyprobe     INFO     End of cycle: sleeping for 2 seconds
2015-06-04 17:35:06,676 dummyprobe     INFO     Started cycle at 2015-06-04T17:35:06.675+01:00
2015-06-04 17:35:07,022 jelh           INFO     Flushing 109 records
2015-06-04 17:35:07,259 dummyprobe     INFO     Finished cycle at 2015-06-04T17:35:07.260+01:00
2015-06-04 17:35:07,260 dummyprobe     INFO     End of cycle: sleeping for 10 seconds
2015-06-04 17:35:09,236 jelh           INFO     Flushing 1000 records
...
```
##### 10. Access kibana dashboard
Lastly, let's configure a kibana dashboard to explore the information:

Access kibana3 to create a dashboard for `[linuxindex-]YYYY.MM.DD`.  
Create three rows.  
1. First with a frequency histogram and a mean histogram for `value` field.  
2. Second: Three terms panels, first for `class` field, second for `host` field and last for `metrics` field. These will be usefull for data exploration (click on any to filter your data).
3. On the last row, place your table to list your documents.

It'll look like this (aparently useless):  
![](https://github.com/filipealmeida/probespawner/blob/master/docs/probespawner.linuxmetrics.dashboard.0.png)

The second row will be great to filter and explore your data.  
Let's select `RES`, the resident memory of every process.  
Now, the `MEAN OF VALUE` panel will show something like this, the average resident memory each process is ocupying:  
![](https://github.com/filipealmeida/probespawner/blob/master/docs/probespawner.linuxmetrics.dashboard.1.png)

Should you select the `uptime` class, you'll have the following `metrics` available:
![](https://github.com/filipealmeida/probespawner/blob/master/docs/probespawner.linuxmetrics.dashboard.2.png)

Clicking on `load1`, you can now visualize on the `MEAN OF VALUE` panel the average of the last minute load average available.  
![](https://github.com/filipealmeida/probespawner/blob/master/docs/probespawner.linuxmetrics.dashboard.3.png)

If you had selected `users` you'd be seeing the number of users as time goes by and so on.  
There are many creative ways to index your data and to setup such a dashboard.  
In any case, this shows a way to visualize the information collected, many things can be done after you have the info.  
This document means only to illustrate on how to collect interesting data with probespawner.  


